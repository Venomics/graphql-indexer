# graphql-indexer

GraphQL powered Venom blockchain indexer and data marts builder for the [Venomics](https://venomics.xyz/)

## Overall architecture

Indexer services (see [docker-compose.yml](./docker-compose.yml)):
* Postgres DB
* Kafka
* streamer
* message_indexer
* event_decoder

### streamer

Starting point for the indexing process. Listens to the GrqphQL stream of new messages 
and  pushes messages to ``venom_transactions`` Kafka topic.

### message_indexer

Second stage. Listens to the ``venom_transactions`` Kafka topic
and perform two tasks:
1. Store messages in the DB
2. Pushes ids of external messages to ``venom_messages_decode_queue`` Kafka topic.

### event_decoder

Third stage. Listens to the  ``venom_messages_decode_queue`` Kafka topic and requests decoding service 
at https://testnetverify.venomscan.com. After decoding DEX-related events it
handles update of ``dex_pair`` and ``tokens_info`` tables.

## ETL

There are two Airflow jobs to populate next layer data marts from the raw stage generated by the Indexer:
* [top_token_datamart](./etl/top_token_datamart.py) - generates current tokens ratings with actual prices and volumes
* [tvl_datamart](./etl/tvl_datamart.py) - generates actual TVL for all DEX pools

## DB structure

DB structure: [db.sql](./db.sql)

* messages - raw blockchain messages
* events - decoded external messages (events)
* exchange_event - structured Exchange event
* sync_event - structured Sync event (DEX pool balance)
* dex_pair -  information about DEX pairs recovered from the sync_event
* tokens_info - information about active tokens (involved in swaps)
* top_tokens_datamart - data mart built by ETL process, contains information about top tokens (prices, volumes, ...)
* tvl_history - data mart with the history of TVL